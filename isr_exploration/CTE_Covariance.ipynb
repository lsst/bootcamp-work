{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CTI origin-location \n",
    "Calculate Covariance to the next line (//)  or next pixel (serial) in slices (along line and column)  of image difference  \n",
    "to look for covariance variation over line or column , to identify if CTI effects are in a specific location in the device .\n",
    "This is also useful to identify trap ( = negative correlation at low flux ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system imports\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# LSST stack imports\n",
    "from lsst.daf.persistence import Butler\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.ip.isr import IsrTask\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.math as afwMath\n",
    "\n",
    "\n",
    "# Firefly client imports\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the config for the ISR task.  This essentially turns off all processing other than overscan and bias correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr_config = IsrTask.ConfigClass()\n",
    "\n",
    "isr_config.doDark=False\n",
    "isr_config.doFlat=False\n",
    "isr_config.doFringe=False\n",
    "isr_config.doDefect=False\n",
    "isr_config.doAddDistortionModel=False\n",
    "isr_config.doLinearize=False\n",
    "isr_config.doSaturationInterpolation=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `IsrTask` with the above configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr = IsrTask(config=isr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTCAMP_REPO_DIR = '/project/bootcamp/repo_RTM-007/'\n",
    "butler = Butler(BOOTCAMP_REPO_DIR)\n",
    "visits = butler.queryMetadata('raw', ['visit'], dataId={'imageType': 'FLAT', 'testType': 'SFLAT_500'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched exptimes\n",
      "35\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# Handle non-even series of images\n",
    "# Tried to do something more clever, but not fully worked through yet\n",
    "#etimes = []\n",
    "#for visit in visits:\n",
    "#    dId = {'visit': visit, 'detector': 2}\n",
    "#    raw = butler.get('raw', **dId)\n",
    "#    etimes.append(raw.getInfo().getVisitInfo().getExposureTime())\n",
    "#exposure_times = numpy.array(etimes)\n",
    "#unique_times, unique_indicies = numpy.unique(exposure_times, return_index=True)\n",
    "#print(unique_indicies)\n",
    "#indicies = unique_indicies.tolist() + [exposure_times.size - 1]\n",
    "\n",
    "# Brute force for RTM-007, but inaccurate for all cases\n",
    "bad_visits = []\n",
    "for visit1, visit2 in zip(visits[:-1:2], visits[1::2]):\n",
    "    dId = {'visit': visit1, 'detector': 2}\n",
    "    raw1 = butler.get('raw', **dId)\n",
    "    time1 = raw1.getInfo().getVisitInfo().getExposureTime()\n",
    "    \n",
    "    # Get ISR data for second image\n",
    "    dId = {'visit': visit2, 'detector': 2}\n",
    "    raw2 = butler.get('raw', **dId)\n",
    "    time2 = raw2.getInfo().getVisitInfo().getExposureTime()\n",
    "    if abs(time1 - time2) > 0.01:\n",
    "        print(\"Mismatched exptimes\")\n",
    "        bad_visits.append(visit1)\n",
    "\n",
    "print(len(visits))\n",
    "for bad_visit in bad_visits:\n",
    "    visits.remove(bad_visit)\n",
    "print(len(visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We saw 17 pair of images \n"
     ]
    }
   ],
   "source": [
    "### config to compute the varaicne and covaraince \n",
    "#number of pair\n",
    "nb_pair=int(len(visits)/2)\n",
    "print('We saw %d pair of images '% (nb_pair))\n",
    "#\n",
    "# Cliping in number of sigma for the variance and mean\n",
    "# default : not used \n",
    "#clip_sig=4.\n",
    "# Size of the cov matrix \n",
    "#ncov_x=2\n",
    "#ncov_y=2\n",
    "ncov_x=2\n",
    "ncov_y=2\n",
    "# The cov matrix will be computed in nx*ny bin for each  amplifier , not just 1 cov matrix per amplifier ( amplifier is subdivided in nx*ny boxes)    \n",
    "nx=2\n",
    "ny=2 \n",
    "# size of the ccd   ==> we should make this agnostic \n",
    "# x : column , y : line , first & last+1 \n",
    "# in x exclusion region , and box size : should be function of the amplifier used ... we do for the worse case : side device\n",
    "xoff=25\n",
    "# first column to use\n",
    "xf=0 + xoff   \n",
    "# last column+1 to use \n",
    "xl=512 - xoff   \n",
    "# y exclusion region , and box size \n",
    "yoff=10\n",
    "#first line to use \n",
    "yf=0 + yoff     \n",
    "# last line + 1 to use \n",
    "yl=2002  - yoff\n",
    "# step size\n",
    "ystep=int((yl-yf)/ny)\n",
    "xstep=int((xl-xf)/nx)\n",
    "#\n",
    "# Temporary strorage before averaging over all pair of a given flux\n",
    "temp_var=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_evar=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_nentry=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_mean=np.zeros((16,ny,nx, nb_pair))\n",
    "temp_time=np.zeros(( nb_pair))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1093.2821044921875 1104.7463989257812\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1108.7801513671875 1103.0076904296875\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1093.1693115234375 1095.5267333984375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1098.1515502929688 1114.4337158203125\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1106.1041870117188 1112.6805419921875\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1114.4190673828125 1113.2086181640625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1100.9881591796875 1109.767822265625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1117.9417724609375 1107.67822265625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1108.68701171875 1111.8208618164062\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1110.09912109375 1103.334716796875\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1110.30810546875 1109.9993896484375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1106.9606323242188 1105.6910400390625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 55422.6171875 55154.4453125\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 55154.486328125 55133.55859375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 55093.21875 54647.015625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 55126.88671875 55134.08984375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 54820.25390625 54978.54296875\n"
     ]
    }
   ],
   "source": [
    "# --- select the device you want to ananlyse \n",
    "ccd_id=8\n",
    "# channel id , for the time beeing put 12\n",
    "k=12\n",
    "# counter of the number of pari seen\n",
    "npair=0\n",
    "for visit1, visit2 in zip(visits[:-1:2], visits[1::2]): # loop over pairs of images\n",
    "    # Get ISR data for first image\n",
    "    dId = {'visit': visit1, 'detector': ccd_id }\n",
    "    raw1 = butler.get('raw', **dId)\n",
    "    bias1 = butler.get('bias', **dId)\n",
    "    time1 = raw1.getInfo().getVisitInfo().getExposureTime()\n",
    "    \n",
    "    # Get ISR data for second image\n",
    "    dId = {'visit': visit2, 'detector': ccd_id }\n",
    "    raw2 = butler.get('raw', **dId)\n",
    "    bias2 = butler.get('bias', **dId)\n",
    "    time2 = raw2.getInfo().getVisitInfo().getExposureTime()\n",
    "    if abs(time1 - time2) > 0.01:\n",
    "        print(\"Mismatched exptimes\")\n",
    "        continue\n",
    "    # save the exposure time for this pair     \n",
    "    temp_time[npair]=time1\n",
    "    # run ISR on both images\n",
    "    result1 = isr.run(raw1, bias=bias1)\n",
    "    result2 = isr.run(raw2, bias=bias2)\n",
    "    \n",
    "    detector = result1.exposure.getDetector()\n",
    "    #  \n",
    "    amp = detector[k]\n",
    "    #\n",
    "    sub_im1 = result1.exposure.getMaskedImage()[amp.getBBox()]\n",
    "    print ('first image of the pair  ready')\n",
    "    #arr1 = sub_im1.getImage().getArray()\n",
    "    sub_im2 = result2.exposure.getMaskedImage()[amp.getBBox()]\n",
    "    print ('second image of the pair  ready')\n",
    "    #arr2 = sub_im2.getImage().getArray()\n",
    "    #print(sub_im1.getImage().getArray().shape)\n",
    "    \n",
    "    stats_im1 = afwMath.makeStatistics(sub_im1, afwMath.MEDIAN)\n",
    "    stats_im2 = afwMath.makeStatistics(sub_im2, afwMath.MEDIAN)\n",
    "    \n",
    "    avg_flux1 = stats_im1.getValue(afwMath.MEDIAN)\n",
    "    avg_flux2 = stats_im2.getValue(afwMath.MEDIAN)\n",
    "    print('Flux level of the 2 images =',avg_flux1, avg_flux2)\n",
    "    \n",
    "    avg_flux = (avg_flux1 + avg_flux2) / 2\n",
    "    \n",
    "    sub_im1 /= avg_flux1\n",
    "    sub_im2 /= avg_flux2\n",
    "    \n",
    "    # image difference on re-normed flux \n",
    "    diff_im = sub_im1.clone()\n",
    "    diff_im -= sub_im2\n",
    "    \n",
    "    diff_im *= avg_flux\n",
    "    #\n",
    "    diff_array=diff_im.getImage().clone().getArray()\n",
    "    \n",
    "    # image average \n",
    "    avg_im  =   sub_im1.clone()\n",
    "    avg_im  +=  sub_im2\n",
    "    \n",
    "    avg_im  *=  avg_flux \n",
    "    #\n",
    "    avg_array=avg_im.getImage().clone().getArray()\n",
    "    # compute the var and covariance within image boxes\n",
    "    ix=0\n",
    "    iy=0\n",
    "    # loop on the different sub-boxes of a channel\n",
    "    for y in range(yf,yl,ystep) :\n",
    "        for x in range(xf,xl,xstep) :\n",
    "            # for the current box the image diff\n",
    "            # we should take a truncted mean ... but we will take a median for the moment \n",
    "            temp_mean[k,iy,ix,npair]=np.median(avg_array[y:y+ystep,x:x+xstep])\n",
    "            #\n",
    "            wd=diff_array[y:y+ystep,x:x+xstep]\n",
    "            # compute the various variance and corvariance \n",
    "            for i in range(ncov_y) : \n",
    "                for j in range (ncov_x) : \n",
    "                    v1=wd[i:ystep,j:xstep]*wd[0:ystep-i,0:xstep-j]\n",
    "                    if i != 0 and j != 0 :\n",
    "                        # the initial version was a masked array - clipped to 4 sigma ... for the moment put it to a fix value\n",
    "                        # n1=v1.count()\n",
    "                        n1=ystep*xstep\n",
    "                        v2=wd[i:ystep,0:xstep-j]*wd[0:ystep-i,j:xstep]\n",
    "                        #n2=v2.count()\n",
    "                        n2=ystep*xstep\n",
    "                        temp_nentry[k,iy,ix,i,j,npair]=n1+n2\n",
    "                        #weighted average of the mean in function of the statistic in each subf sample \n",
    "                        temp_var[k,iy,ix,i,j,npair]=(v1.mean()*n1+v2.mean()*n2)/temp_nentry[k,iy,ix,i,j,npair]/2.\n",
    "                        temp_evar[k,iy,ix,i,j,npair]=(v1.std()*n1+v2.std()*n2)/temp_nentry[k,iy,ix,i,j,npair]/2.\n",
    "                    else:\n",
    "                        # the initial version was a masked array - clipped to 4 sigma ... for the moment put it to a fix value\n",
    "                        #temp_nentry[k,iy,ix,i,j,npair]=v1.count()\n",
    "                        temp_nentry[k,iy,ix,i,j,npair]=ystep*xstep\n",
    "                        temp_var[k,iy,ix,i,j,npair]=v1.mean()/2.\n",
    "                        temp_evar[k,iy,ix,i,j,npair]=v1.std()/2.\n",
    "            #diff_std=wd.std()\n",
    "            #diff_var=diff_std**2\n",
    "            ix+=1\n",
    "        #\n",
    "        ix=0\n",
    "        iy+=1\n",
    "    # move to next pair of image\n",
    "    npair+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over the pairs  of same exposure time \n",
    "itime=np.argsort(temp_time)\n",
    "t_ref=temp_time[itime[0]]\n",
    "selected_pair=[itime[0]]\n",
    "results_final=[]\n",
    "for ipair in range(1,npair) :\n",
    "    if temp_time[itime[ipair]]>t_ref :\n",
    "        results_final.append({'mean':temp_mean[:,:,:,selected_pair].mean(axis=3),\n",
    "                              'var':temp_var[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'evar':temp_evar[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'nentry':temp_nentry[:,:,:,:,:,selected_pair].sum(axis=5),\n",
    "                              'npair':len(selected_pair),\n",
    "                              'time':temp_time[selected_pair].mean()})\n",
    "        selected_pair=[]\n",
    "        t_ref=temp_time[itime[ipair]]\n",
    "    #\n",
    "    selected_pair.append(itime[ipair])\n",
    "# average the last serie of pair \n",
    "results_final.append({'mean':temp_mean[:,:,:,selected_pair].mean(axis=3),\n",
    "                              'var':temp_var[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'evar':temp_evar[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'nentry':temp_nentry[:,:,:,:,:,selected_pair].sum(axis=5),\n",
    "                              'npair':len(selected_pair),\n",
    "                              'time':temp_time[selected_pair].mean()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposure time  0.6769999999999999  used  12  pair(s) of images\n",
      "cov(1,0) for the 4 image parts and errors\n",
      "[[3.1804881  3.46166729]\n",
      " [2.62278934 1.38096473]]\n",
      "[[1.05704864 1.0633178 ]\n",
      " [1.05821937 1.05926127]]\n",
      "cov(1,1) for the 4 image parts and errors\n",
      "[[0.25228822 0.66348328]\n",
      " [1.0005815  0.39103477]]\n",
      "[[0.74743969 0.75075324]\n",
      " [0.74848525 0.74865348]]\n",
      "cov(0,1) for the 4 image parts and errors\n",
      "[[ 1.10474779  0.75022311]\n",
      " [-0.72157676  0.11841664]]\n",
      "[[1.05685997 1.0587852 ]\n",
      " [1.05775484 1.05923932]]\n",
      "we got comparable variance and errors \n",
      "[[1752.0316569  1756.58180745]\n",
      " [1754.23225911 1756.07166545]]\n",
      "[[1.49687827 2.15925127]\n",
      " [1.49702633 1.49713446]]\n",
      "and comparable flux\n",
      "[[2211.92889404 2213.04833984]\n",
      " [2214.62880452 2215.28885905]]\n",
      "exposure time  33.746  used  5  pair(s) of images\n",
      "cov(1,0) for the 4 image parts and errors\n",
      "[[472.11358948 511.17453918]\n",
      " [423.52160034 250.52746124]]\n",
      "[[72.55929893 86.35822778]\n",
      " [78.98060376 70.39301077]]\n",
      "cov(1,1) for the 4 image parts and errors\n",
      "[[393.5452652  252.00842838]\n",
      " [374.10504622 266.02642574]]\n",
      "[[50.58249171 55.6162619 ]\n",
      " [54.86579512 49.80264699]]\n",
      "cov(0,1) for the 4 image parts and errors\n",
      "[[1068.68231201  878.24858398]\n",
      " [ 909.33121338  970.69741211]]\n",
      "[[74.06608185 78.39209044]\n",
      " [78.29956245 70.46559167]]\n",
      "we got comparable variance and errors \n",
      "[[75544.846875 75786.009375]\n",
      " [75540.334375 75311.86875 ]]\n",
      "[[109.39120851 145.79585509]\n",
      " [112.39972843  99.47363399]]\n",
      "and comparable flux\n",
      "[[110044.246875  110097.8296875]\n",
      " [110184.759375  110218.8      ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_final)):\n",
    "    print('exposure time ',results_final[i]['time'],' used ',results_final[i]['npair'],' pair(s) of images')\n",
    "    print('cov(1,0) for the 4 image parts and errors')\n",
    "    print(results_final[i]['var'][k,:,:,0,1])\n",
    "    print(results_final[i]['evar'][k,:,:,0,1]/np.sqrt(results_final[i]['nentry'][k,:,:,0,1]))\n",
    "    print('cov(1,1) for the 4 image parts and errors')\n",
    "    print(results_final[i]['var'][k,:,:,1,1])\n",
    "    print(results_final[i]['evar'][k,:,:,1,1]/np.sqrt(results_final[i]['nentry'][k,:,:,1,1]))\n",
    "    print('cov(0,1) for the 4 image parts and errors')\n",
    "    print(results_final[i]['var'][k,:,:,1,0])\n",
    "    print(results_final[i]['evar'][k,:,:,1,0]/np.sqrt(results_final[i]['nentry'][k,:,:,1,0]))\n",
    "    print('we got comparable variance and errors ')\n",
    "    print(results_final[i]['var'][k,:,:,0,0])\n",
    "    print(results_final[i]['evar'][k,:,:,0,0]/np.sqrt(results_final[i]['nentry'][k,:,:,0,0]))\n",
    "    print('and comparable flux')\n",
    "    print(results_final[i]['mean'][k,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
