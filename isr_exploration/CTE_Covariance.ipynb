{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CTI origin-location \n",
    "Calculate Covariance to the next line (//)  or next pixel (serial) in slices (along line and column)  of image difference  \n",
    "to look for covariance variation over line or column , to identify if CTI effects are in a specific location in the device .\n",
    "This is also useful to identify trap ( = negative correlation at low flux ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system imports\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# LSST stack imports\n",
    "from lsst.daf.persistence import Butler\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.ip.isr import IsrTask\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.math as afwMath\n",
    "\n",
    "\n",
    "# Firefly client imports\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the config for the ISR task.  This essentially turns off all processing other than overscan and bias correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr_config = IsrTask.ConfigClass()\n",
    "\n",
    "isr_config.doDark=False\n",
    "isr_config.doFlat=False\n",
    "isr_config.doFringe=False\n",
    "isr_config.doDefect=False\n",
    "isr_config.doAddDistortionModel=False\n",
    "isr_config.doLinearize=False\n",
    "isr_config.doSaturationInterpolation=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `IsrTask` with the above configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr = IsrTask(config=isr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTCAMP_REPO_DIR = '/project/bootcamp/repo_RTM-007/'\n",
    "butler = Butler(BOOTCAMP_REPO_DIR)\n",
    "visits = butler.queryMetadata('raw', ['visit'], dataId={'imageType': 'FLAT', 'testType': 'SFLAT_500'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched exptimes\n",
      "35\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# Handle non-even series of images\n",
    "# Tried to do something more clever, but not fully worked through yet\n",
    "#etimes = []\n",
    "#for visit in visits:\n",
    "#    dId = {'visit': visit, 'detector': 2}\n",
    "#    raw = butler.get('raw', **dId)\n",
    "#    etimes.append(raw.getInfo().getVisitInfo().getExposureTime())\n",
    "#exposure_times = numpy.array(etimes)\n",
    "#unique_times, unique_indicies = numpy.unique(exposure_times, return_index=True)\n",
    "#print(unique_indicies)\n",
    "#indicies = unique_indicies.tolist() + [exposure_times.size - 1]\n",
    "\n",
    "# Brute force for RTM-007, but inaccurate for all cases\n",
    "bad_visits = []\n",
    "for visit1, visit2 in zip(visits[:-1:2], visits[1::2]):\n",
    "    dId = {'visit': visit1, 'detector': 2}\n",
    "    raw1 = butler.get('raw', **dId)\n",
    "    time1 = raw1.getInfo().getVisitInfo().getExposureTime()\n",
    "    \n",
    "    # Get ISR data for second image\n",
    "    dId = {'visit': visit2, 'detector': 2}\n",
    "    raw2 = butler.get('raw', **dId)\n",
    "    time2 = raw2.getInfo().getVisitInfo().getExposureTime()\n",
    "    if abs(time1 - time2) > 0.01:\n",
    "        print(\"Mismatched exptimes\")\n",
    "        bad_visits.append(visit1)\n",
    "\n",
    "print(len(visits))\n",
    "for bad_visit in bad_visits:\n",
    "    visits.remove(bad_visit)\n",
    "print(len(visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We saw 12 pair of images \n"
     ]
    }
   ],
   "source": [
    "### config to compute the varaicne and covaraince \n",
    "#number of pair\n",
    "nb_pair=int(len(visits)/2)\n",
    "print('We saw %d pair of images '% (nb_pair))\n",
    "#\n",
    "# Cliping in number of sigma for the variance and mean\n",
    "# default : not used \n",
    "#clip_sig=4.\n",
    "# Size of the cov matrix \n",
    "#ncov_x=2\n",
    "#ncov_y=2\n",
    "ncov_x=2\n",
    "ncov_y=2\n",
    "# The cov matrix will be computed in nx*ny bin for each  amplifier , not just 1 cov matrix per amplifier ( amplifier is subdivided in nx*ny boxes)    \n",
    "nx=2\n",
    "ny=2 \n",
    "# size of the ccd   ==> we should make this agnostic \n",
    "# x : column , y : line , first & last+1 \n",
    "# in x exclusion region , and box size : should be function of the amplifier used ... we do for the worse case : side device\n",
    "xoff=25\n",
    "# first column to use\n",
    "xf=0 + xoff   \n",
    "# last column+1 to use \n",
    "xl=512 - xoff   \n",
    "# y exclusion region , and box size \n",
    "yoff=10\n",
    "#first line to use \n",
    "yf=0 + yoff     \n",
    "# last line + 1 to use \n",
    "yl=2002  - yoff\n",
    "# step size\n",
    "ystep=int((yl-yf)/ny)\n",
    "xstep=int((xl-xf)/nx)\n",
    "#\n",
    "# Temporary strorage before averaging over all pair of a given flux\n",
    "temp_var=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_evar=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_nentry=np.zeros((16,ny,nx,ncov_y,ncov_x, nb_pair))\n",
    "temp_mean=np.zeros((16,ny,nx, nb_pair))\n",
    "temp_time=np.zeros(( nb_pair))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1050.6278076171875 1061.7132568359375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1065.46337890625 1060.052490234375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1050.593994140625 1052.67822265625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1055.298095703125 1071.1209716796875\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1063.03173828125 1069.314208984375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1071.1331787109375 1069.8699340820312\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1057.985107421875 1066.541015625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1074.68798828125 1064.5687255859375\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1065.3431396484375 1068.4072265625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1066.7623901367188 1060.1908569335938\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1067.113037109375 1066.59765625\n",
      "first image of the pair  ready\n",
      "second image of the pair  ready\n",
      "Flux level of the 2 images = 1063.8416748046875 1062.673095703125\n"
     ]
    }
   ],
   "source": [
    "gain = {}\n",
    "exp_time = {}\n",
    "\n",
    "visits = visits[0:24]\n",
    "\n",
    "i = 1\n",
    "# counter of the number of pari seen\n",
    "npair=0\n",
    "for visit1, visit2 in zip(visits[:-1:2], visits[1::2]): # loop over pairs of images\n",
    "    # Get ISR data for first image\n",
    "    dId = {'visit': visit1, 'detector': 2}\n",
    "    raw1 = butler.get('raw', **dId)\n",
    "    bias1 = butler.get('bias', **dId)\n",
    "    time1 = raw1.getInfo().getVisitInfo().getExposureTime()\n",
    "    \n",
    "    # Get ISR data for second image\n",
    "    dId = {'visit': visit2, 'detector': 2}\n",
    "    raw2 = butler.get('raw', **dId)\n",
    "    bias2 = butler.get('bias', **dId)\n",
    "    time2 = raw2.getInfo().getVisitInfo().getExposureTime()\n",
    "    if abs(time1 - time2) > 0.01:\n",
    "        print(\"Mismatched exptimes\")\n",
    "        continue\n",
    "    # save the exposure time for this pair     \n",
    "    temp_time[npair]=time1\n",
    "    # run ISR on both images\n",
    "    result1 = isr.run(raw1, bias=bias1)\n",
    "    result2 = isr.run(raw2, bias=bias2)\n",
    "    \n",
    "    detector = result1.exposure.getDetector()\n",
    "    #   channel id , for the time beeing put 3\n",
    "    k=3\n",
    "    amp = detector[k]\n",
    "    #\n",
    "    sub_im1 = result1.exposure.getMaskedImage()[amp.getBBox()]\n",
    "    print ('first image of the pair  ready')\n",
    "    #arr1 = sub_im1.getImage().getArray()\n",
    "    sub_im2 = result2.exposure.getMaskedImage()[amp.getBBox()]\n",
    "    print ('second image of the pair  ready')\n",
    "    #arr2 = sub_im2.getImage().getArray()\n",
    "    #print(sub_im1.getImage().getArray().shape)\n",
    "    \n",
    "    stats_im1 = afwMath.makeStatistics(sub_im1, afwMath.MEDIAN)\n",
    "    stats_im2 = afwMath.makeStatistics(sub_im2, afwMath.MEDIAN)\n",
    "    \n",
    "    avg_flux1 = stats_im1.getValue(afwMath.MEDIAN)\n",
    "    avg_flux2 = stats_im2.getValue(afwMath.MEDIAN)\n",
    "    print('Flux level of the 2 images =',avg_flux1, avg_flux2)\n",
    "    \n",
    "    avg_flux = (avg_flux1 + avg_flux2) / 2\n",
    "    \n",
    "    sub_im1 /= avg_flux1\n",
    "    sub_im2 /= avg_flux2\n",
    "    \n",
    "    # image difference on re-normed flux \n",
    "    diff_im = sub_im1.clone()\n",
    "    diff_im -= sub_im2\n",
    "    \n",
    "    diff_im *= avg_flux\n",
    "    #\n",
    "    diff_array=diff_im.getImage().clone().getArray()\n",
    "    \n",
    "    # image average \n",
    "    avg_im  =   sub_im1.clone()\n",
    "    avg_im  +=  sub_im2\n",
    "    \n",
    "    avg_im  *=  avg_flux \n",
    "    #\n",
    "    avg_array=avg_im.getImage().clone().getArray()\n",
    "    # compute the var and covariance within image boxes\n",
    "    ix=0\n",
    "    iy=0\n",
    "    # loop on the different sub-boxes of a channel\n",
    "    for y in range(yf,yl,ystep) :\n",
    "        for x in range(xf,xl,xstep) :\n",
    "            # for the current box the image diff\n",
    "            # we should take a truncted mean ... but we will take a median for the moment \n",
    "            temp_mean[k,iy,ix,npair]=np.median(avg_array[y:y+ystep,x:x+xstep])\n",
    "            #\n",
    "            wd=diff_array[y:y+ystep,x:x+xstep]\n",
    "            # compute the various variance and corvariance \n",
    "            for i in range(ncov_y) : \n",
    "                for j in range (ncov_x) : \n",
    "                    v1=wd[i:ystep,j:xstep]*wd[0:ystep-i,0:xstep-j]\n",
    "                    if i != 0 and j != 0 :\n",
    "                        # the initial version was a masked array - clipped to 4 sigma ... for the moment put it to a fix value\n",
    "                        # n1=v1.count()\n",
    "                        n1=ystep*xstep\n",
    "                        v2=wd[i:ystep,0:xstep-j]*wd[0:ystep-i,j:xstep]\n",
    "                        #n2=v2.count()\n",
    "                        n2=ystep*xstep\n",
    "                        temp_nentry[k,iy,ix,i,j,npair]=n1+n2\n",
    "                        #weighted average of the mean in function of the statistic in each subf sample \n",
    "                        temp_var[k,iy,ix,i,j,npair]=(v1.mean()*n1+v2.mean()*n2)/temp_nentry[k,iy,ix,i,j,npair]\n",
    "                        temp_evar[k,iy,ix,i,j,npair]=(v1.std()*n1+v2.std()*n2)/temp_nentry[k,iy,ix,i,j,npair]\n",
    "                    else:\n",
    "                        # the initial version was a masked array - clipped to 4 sigma ... for the moment put it to a fix value\n",
    "                        #temp_nentry[k,iy,ix,i,j,npair]=v1.count()\n",
    "                        temp_nentry[k,iy,ix,i,j,npair]=ystep*xstep\n",
    "                        temp_var[k,iy,ix,i,j,npair]=v1.mean()\n",
    "                        temp_evar[k,iy,ix,i,j,npair]=v1.std()\n",
    "            #diff_std=wd.std()\n",
    "            #diff_var=diff_std**2\n",
    "            ix+=1\n",
    "        #\n",
    "        ix=0\n",
    "        iy+=1\n",
    "    # move to next pair of image\n",
    "    npair+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over the pairs  of same exposure time \n",
    "itime=np.argsort(temp_time)\n",
    "t_ref=temp_time[itime[0]]\n",
    "selected_pair=[itime[0]]\n",
    "results_final=[]\n",
    "for ipair in range(1,npair) :\n",
    "    if temp_time[itime[ipair]]>t_ref :\n",
    "        results_final.append({'mean':temp_mean[:,:,:,selected_pair].mean(axis=3),\n",
    "                              'var':temp_var[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'evar':temp_evar[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'nentry':temp_nentry[:,:,:,:,:,selected_pair].sum(axis=5),\n",
    "                              'npair':len(selected_pair),\n",
    "                              'time':temp_time[selected_pair].mean()})\n",
    "        selected_pair=[]\n",
    "    #\n",
    "    selected_pair.append(itime[ipair])\n",
    "# average the last serie of pair \n",
    "results_final.append({'mean':temp_mean[:,:,:,selected_pair].mean(axis=3),\n",
    "                              'var':temp_var[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'evar':temp_evar[:,:,:,:,:,selected_pair].mean(axis=5),\n",
    "                              'nentry':temp_nentry[:,:,:,:,:,selected_pair].sum(axis=5),\n",
    "                              'npair':len(selected_pair),\n",
    "                              'time':temp_time[selected_pair].mean()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise ! we get quite different covariance in the # image parts !!!!\n",
      "cov(1,0) for the 4 image parts\n",
      "[[ 6.0703873   0.67166394]\n",
      " [ 1.86618502 17.88805332]]\n",
      "we got comparable variance ???\n",
      "[[3234.71791585 3243.89805094]\n",
      " [3239.93607585 3262.68546549]]\n",
      "and comparable flux ???\n",
      "[[2127.58412679 2128.45277913]\n",
      " [2126.80556234 2127.50295003]]\n"
     ]
    }
   ],
   "source": [
    "print('surprise ! we get quite different covariance in the # image parts !!!!')\n",
    "print('cov(1,0) for the 4 image parts')\n",
    "print(results_final[0]['var'][k,:,:,0,1])\n",
    "print('we got comparable variance ???')\n",
    "print(results_final[0]['var'][k,:,:,0,0])\n",
    "print('and comparable flux ???')\n",
    "print(results_final[0]['mean'][k,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
