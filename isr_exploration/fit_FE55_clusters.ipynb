{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook for determining FE55 gains and camera charge diffusion\n",
    "\n",
    "Eric Charles and Bo Xin\n",
    "\n",
    "References:\n",
    "\n",
    "    o. https://github.com/lsst/bootcamp-work/blob/master/examples/welcome_to_FE55.ipynb\n",
    "\n",
    "    o. https://github.com/lsst-camera-dh/eotest/blob/master/python/lsst/eotest/sensor/fe55_psf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before running this notebook, you'll need to set up the `obs_lsst` package. Before doing the setup procedure below, you might want to run the notebook until it crashes so you see what the error message looks like.\n",
    "\n",
    "Step-by-step instructions:\n",
    "\n",
    "1. Start a terminal in JupyterLab. In the terminal, setup the Stack with the command `source /opt/lsst/software/stack/loadLSST.bash` and then issue the command `setup lsst_distrib` to allow you to run scons in a subsequent step.\n",
    "\n",
    "2. Create and/or switch into a folder where you want to put your local versions of the LSST Stack (e.g., `~/repos`)\n",
    "\n",
    "Run the following commands\n",
    "\n",
    "```\n",
    "git clone https://github.com/lsst/obs_lsstCam.git\n",
    "cd obs_lsstCam\n",
    "setup -j -r .\n",
    "scons\n",
    "```\n",
    "\n",
    "3. Add `setup -k -r path_to_repos/obs_lsstCam` to `$HOME/notebooks/.user_setups`.\n",
    "\n",
    "4. Restart your kernel.\n",
    "\n",
    "Just for fun, check what version of the Stack you are using. This notebook has been tested on `w_2018_45`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# system imports\n",
    "from matplotlib import pylab as plt\n",
    "from scipy.optimize import leastsq\n",
    "import numpy\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# LSST stack imports\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.ip.isr import IsrTask\n",
    "import lsst.afw.detection as afwDetection\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.math as afwMath\n",
    "\n",
    "# Firefly client imports\n",
    "import FE55_psf_func\n",
    "import stats_utils\n",
    "import table_utils\n",
    "from scipy.special import erf, gammaincc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the config for the ISR task.  This essentially turns off all processing other than overscan and bias correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr_config = IsrTask.ConfigClass()\n",
    "\n",
    "isr_config.doDark=False\n",
    "isr_config.doFlat=False\n",
    "isr_config.doFringe=False\n",
    "isr_config.doDefect=False\n",
    "isr_config.doAddDistortionModel=False\n",
    "isr_config.doLinearize=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `IsrTask` with the above configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr = IsrTask(config=isr_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the data necessary to perform ISR.  This is just the raw data and the bias frame.  Note there are multiple integrations.  This notebook only looks at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTCAMP_REPO_DIR= '/project/bootcamp/repo_RTM-007/'\n",
    "butler = Butler(BOOTCAMP_REPO_DIR)\n",
    "print(butler.queryMetadata('raw', ['visit'], dataId={'imageType': 'FE55', 'testType': 'FE55'}))\n",
    "\n",
    "dId = {'visit': 258334666, 'detector': 2}\n",
    "raw = butler.get('raw', **dId)\n",
    "bias = butler.get('bias', **dId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = isr.run(raw, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_utils\n",
    "import table_utils\n",
    "import fe55_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "fits = []\n",
    "detector = result.exposure.getDetector()\n",
    "\n",
    "opt_dict = dict(npars=5, min_npix=9, max_npix=100)\n",
    "ccd_results_list = []\n",
    "\n",
    "for iamp, amp in enumerate(detector):\n",
    "    masked_img = result.exposure.getMaskedImage()\n",
    "    work_img = masked_img[amp.getBBox()]\n",
    "    arr = work_img.getImage().getArray()\n",
    "\n",
    "    flags = afwMath.MEDIAN | afwMath.STDEVCLIP\n",
    "    statistics = afwMath.makeStatistics(work_img, flags) #, ccd.stat_ctrl)\n",
    "    median = statistics.getValue(afwMath.MEDIAN)\n",
    "    stdev = statistics.getValue(afwMath.STDEVCLIP)\n",
    "    \n",
    "    thresh = afwDetection.Threshold(100)\n",
    "    fs = afwDetection.FootprintSet(work_img, thresh) # detect hits\n",
    "    fs = afwDetection.FootprintSet(fs, 2, False) # grow the detection footprints\n",
    "    fs.makeHeavy(work_img)\n",
    "\n",
    "    foots = fs.getFootprints()\n",
    "\n",
    "    results_dict = dict(positions=[],\n",
    "                        zvals=[],\n",
    "                        sigmax=[],\n",
    "                        sigmay=[],\n",
    "                        dn=[],\n",
    "                        x0=[],\n",
    "                        y0=[],\n",
    "                        dn_fp=[],\n",
    "                        chiprob=[],\n",
    "                        chi2=[],\n",
    "                        dof=[],\n",
    "                        maxDN=[],\n",
    "                        p9_data=[],\n",
    "                        p9_model=[],\n",
    "                        prect_data=[],\n",
    "                        xpeak=[],\n",
    "                        ypeak=[],\n",
    "                        a=[],\n",
    "                        b=[],\n",
    "                        c=[])\n",
    "\n",
    "    kwargs_dict = opt_dict.copy()\n",
    "    kwargs_dict.update(results_dict)\n",
    "    kwargs_dict['imarr'] = arr\n",
    "    kwargs_dict['stdev'] = stdev\n",
    "    kwargs_dict['meidan'] = median\n",
    "    \n",
    "    counts = []\n",
    "    \n",
    "    n_failed_fits = 0\n",
    "    n_good_fits = 0\n",
    "    \n",
    "    for foot in foots:\n",
    "        if foot.getImageArray().size < 25:  # throw out big footprints/CRs since we know the hits should be in a single pixel modulo the charge diffusion.\n",
    "            counts.append(numpy.sum(foot.getImageArray()))\n",
    "        results = fe55_utils.fit_single_footprint(foot, **kwargs_dict)\n",
    "        \n",
    "        if results == 0:\n",
    "            n_good_fits += 1 \n",
    "        else:\n",
    "            n_failed_fits += 1\n",
    "\n",
    "    ccd_results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = dict(sigmax='f',\n",
    "                 sigmay='f',\n",
    "                 dn='f',\n",
    "                 x0='f',\n",
    "                 y0='f',                 \n",
    "                 dn_fp='f',\n",
    "                 chiprob='f',\n",
    "                 chi2='f',\n",
    "                 dof='i')\n",
    "\n",
    "outfile_base = \"FE55_clusters\"\n",
    "cluster_table_list = []\n",
    "\n",
    "col_list = []\n",
    "for iamp, results_dict in enumerate(ccd_results_list):\n",
    "    cluster_table = table_utils.build_cluster_table(results_dict, cols_dict)\n",
    "    cluster_table_list.append(cluster_table)    \n",
    "    outcluster_file = \"%s_%02i.fits\" % (outfile_base, iamp)\n",
    "    cluster_table.write(outcluster_file, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
