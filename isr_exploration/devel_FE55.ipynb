{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook for determining FE55 gains and camera charge diffusion\n",
    "\n",
    "Eric Charles and Bo Xin\n",
    "\n",
    "References:\n",
    "\n",
    "    o. https://github.com/lsst/bootcamp-work/blob/master/examples/welcome_to_FE55.ipynb\n",
    "\n",
    "    o. https://github.com/lsst-camera-dh/eotest/blob/master/python/lsst/eotest/sensor/fe55_psf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before running this notebook, you'll need to set up the `obs_lsst` package. Before doing the setup procedure below, you might want to run the notebook until it crashes so you see what the error message looks like.\n",
    "\n",
    "Step-by-step instructions:\n",
    "\n",
    "1. Start a terminal in JupyterLab. In the terminal, setup the Stack with the command `source /opt/lsst/software/stack/loadLSST.bash` and then issue the command `setup lsst_distrib` to allow you to run scons in a subsequent step.\n",
    "\n",
    "2. Create and/or switch into a folder where you want to put your local versions of the LSST Stack (e.g., `~/repos`)\n",
    "\n",
    "Run the following commands\n",
    "\n",
    "```\n",
    "git clone https://github.com/lsst/obs_lsstCam.git\n",
    "cd obs_lsstCam\n",
    "setup -j -r .\n",
    "scons\n",
    "```\n",
    "\n",
    "3. Add `setup -k -r path_to_repos/obs_lsstCam` to `$HOME/notebooks/.user_setups`.\n",
    "\n",
    "4. Restart your kernel.\n",
    "\n",
    "Just for fun, check what version of the Stack you are using. This notebook has been tested on `w_2018_45`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system imports\n",
    "from matplotlib import pylab as plt\n",
    "from scipy.optimize import leastsq\n",
    "import numpy\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# LSST stack imports\n",
    "from lsst.daf.persistence import Butler\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.ip.isr import IsrTask\n",
    "import lsst.afw.detection as afwDetection\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.math as afwMath\n",
    "\n",
    "# Firefly client imports\n",
    "from firefly_client import FireflyClient\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import FE55_psf_func\n",
    "import stats_utils\n",
    "from scipy.special import erf, gammaincc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the config for the ISR task.  This essentially turns off all processing other than overscan and bias correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr_config = IsrTask.ConfigClass()\n",
    "\n",
    "isr_config.doDark=False\n",
    "isr_config.doFlat=False\n",
    "isr_config.doFringe=False\n",
    "isr_config.doDefect=False\n",
    "isr_config.doAddDistortionModel=False\n",
    "isr_config.doLinearize=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `IsrTask` with the above configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isr = IsrTask(config=isr_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the data necessary to perform ISR.  This is just the raw data and the bias frame.  Note there are multiple integrations.  This notebook only looks at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTCAMP_REPO_DIR= '/project/bootcamp/repo_RTM-007/'\n",
    "butler = Butler(BOOTCAMP_REPO_DIR)\n",
    "print(butler.queryMetadata('raw', ['visit'], dataId={'imageType': 'FE55', 'testType': 'FE55'}))\n",
    "\n",
    "dId = {'visit': 258334666, 'detector': 2}\n",
    "raw = butler.get('raw', **dId)\n",
    "bias = butler.get('bias', **dId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = isr.run(raw, bias=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the necessary classes for using firefly to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_channel = '{}_test_channel'.format(os.environ['USER'])\n",
    "server = 'https://lsst-lspdev.ncsa.illinois.edu'\n",
    "\n",
    "\n",
    "ff='{}/firefly/slate.html?__wsch={}'.format(server, my_channel)\n",
    "IFrame(ff,800,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afwDisplay.setDefaultBackend('firefly')\n",
    "afw_display = afwDisplay.getDisplay(frame=1, \n",
    "                                    name=my_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaplay the frame after ISR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afw_display.mtv(result.exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the functions doing the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_gaussian(x, params):\n",
    "    (c1, mu1, sigma1, c2, mu2, sigma2) = params\n",
    "    res =  c1 * numpy.exp(-(x - mu1)**2.0/(2.0 * sigma1**2.0)) \\\n",
    "          + c2 * numpy.exp(-(x - mu2)**2.0/(2.0 * sigma2**2.0))\n",
    "    return res\n",
    "\n",
    "def double_gaussian_fit(params, x, y):\n",
    "    fit = double_gaussian( x, params )\n",
    "    return (fit - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_single_footprint(fp, **kwargs):\n",
    "\n",
    "    # input arguments\n",
    "    npars = kwargs.get('npars', 5)\n",
    "    min_npix = kwargs.get('min_npix', 9)\n",
    "    max_npix = kwargs.get('max_npix', 100)\n",
    "    stdev = kwargs.get('stdev')\n",
    "    sigma0 = kwargs.get('sigma0', 0.36)\n",
    "    dn0 = kwargs.get('dn0', 1590./5.)\n",
    "    \n",
    "    # input data\n",
    "    imarr = kwargs.get('imarr')\n",
    "    \n",
    "    # variables we are filling\n",
    "    zvals = kwargs.get('zvals', [])\n",
    "    sigmax = kwargs.get('sigmax', [])\n",
    "    sigmay = kwargs.get('sigmay', [])\n",
    "    dn = kwargs.get('dn', [])\n",
    "    x0 = kwargs.get('x0', [])\n",
    "    y0 = kwargs.get('y0', [])\n",
    "    aList = kwargs.get('a', [])\n",
    "    bList = kwargs.get('b', [])\n",
    "    cList = kwargs.get('c', [])\n",
    "    dn_fp = kwargs.get('dn_fp', [])\n",
    "    chiprob = kwargs.get('chiprob', [])\n",
    "    chi2s = kwargs.get('chi2s', [])\n",
    "    dofs = kwargs.get('dofs', [])\n",
    "    maxDNs = kwargs.get('maxDN', [])\n",
    "    p9_data = kwargs.get('p9_data', [])\n",
    "    p9_model = kwargs.get('p9_model', [])\n",
    "    prect_data = kwargs.get('prect_data', [])\n",
    "    xpeak = kwargs.get('xpeak', [])\n",
    "    ypeak = kwargs.get('ypeak', [])\n",
    "    \n",
    "    if fp.getArea() < min_npix or fp.getArea() > max_npix:            \n",
    "        return -1\n",
    "    spans = fp.getSpans()\n",
    "    positions = []\n",
    "    zvals = []\n",
    "    peak = [pk for pk in fp.getPeaks()][0]\n",
    "    dn_sum = 0\n",
    "    a_0 = 0.0\n",
    "    b_0 = 0.0\n",
    "    c_0 = 100.\n",
    "    \n",
    "    for span in spans:\n",
    "        y = span.getY()\n",
    "        for x in range(span.getX0(), span.getX1() + 1):\n",
    "            ym = y%imarr.shape[0]\n",
    "            xm = x%imarr.shape[1]\n",
    "            zvals.append(imarr[ym][xm])\n",
    "            dn_sum += imarr[ym][xm]\n",
    "            positions.append((x, y))\n",
    "                \n",
    "    try:\n",
    "        # Use clipped stdev as DN error estimate for all pixels\n",
    "        dn_errors = stdev*numpy.ones(len(positions))\n",
    "        if npars == 5:\n",
    "            p0 = (peak.getIx(), peak.getIy(), sigma0, sigma0, dn0, a_0, b_0, c_0)\n",
    "            pars, _ = leastsq(FE55_psf_func.residuals, p0, args=(positions, zvals, dn_errors))\n",
    "            sigx = pars[2]\n",
    "            sigy = pars[3]\n",
    "            dnval = pars[4]\n",
    "            aval = pars[5]\n",
    "            bval = pars[6]\n",
    "            cval = pars[7]\n",
    "        else:\n",
    "            p0 = (peak.getIx(), peak.getIy(), sigma0, dn0, a_0, b_0, c_0)\n",
    "            pars, _ = leastsq(FE55_psf_func.residuals_single, p0, args=(positions, zvals, dn_errors))\n",
    "            sigx = pars[2]\n",
    "            sigy = pars[2]\n",
    "            dnval = pars[3]\n",
    "            aval = pars[4]\n",
    "            bval = pars[5]\n",
    "            cval = pars[6]\n",
    "        chi2 = FE55_psf_func.chisq(positions, zvals, pars[0], pars[1], sigx, sigy, dnval, aval, bval, cval, dn_errors)\n",
    "        dof = fp.getArea() - npars\n",
    "        prob = gammaincc(dof/2., chi2/2.)        \n",
    "        if prob < 1e-2:\n",
    "            return -1\n",
    "        if npars == 5:            \n",
    "            sigmax.append(pars[2])\n",
    "            sigmay.append(pars[3])\n",
    "            dn.append(pars[4])\n",
    "            aList.append(pars[5])\n",
    "            bList.append(pars[6])\n",
    "            cList.append(pars[7])\n",
    "        else:\n",
    "            sigmax.append(pars[2])\n",
    "            sigmay.append(pars[2])\n",
    "            dn.append(pars[3])\n",
    "            aList.append(pars[4])\n",
    "            bList.append(pars[5])\n",
    "            cList.append(pars[6])\n",
    "        x0.append(pars[0])\n",
    "        y0.append(pars[1])\n",
    "        dn_fp.append(dn_sum)\n",
    "        chi2s.append(chi2)\n",
    "        dofs.append(dof)\n",
    "        maxDNs.append(max(zvals))\n",
    "        try:\n",
    "            #p9_data_row, p9_model_row \\\n",
    "            #    = p9_values(peak, imarr, x0[-1], y0[-1], sigmax[-1],\n",
    "            #                sigmay[-1], dn[-1])\n",
    "            #prect_data_row = prect_values(peak,imarr)\n",
    "            #p9_data.append(p9_data_row)\n",
    "            #p9_model.append(p9_model_row)\n",
    "            #prect_data.append(prect_data_row)\n",
    "            xpeak.append(peak.getIx())\n",
    "            ypeak.append(peak.getIy())\n",
    "        except IndexError:\n",
    "            [item.pop() for item in (x0, y0, sigmax, sigmay,\n",
    "                                    dn, dn_fp, chiprob,\n",
    "                                    chi2s, dofs, maxDNs)] \n",
    "    except RuntimeError:\n",
    "        return -1\n",
    "            \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over amps and fit a double gaussian to the distribution of counts in detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_base = \"FE55_clusters\"\n",
    "xs = []\n",
    "ys = []\n",
    "fits = []\n",
    "detector = result.exposure.getDetector()\n",
    "\n",
    "opt_dict = dict(npars=5, min_npix=9, max_npix=100)\n",
    "ccd_results_list = []\n",
    "\n",
    "for iamp, amp in enumerate(detector):\n",
    "    masked_img = result.exposure.getMaskedImage()\n",
    "    work_img = masked_img[amp.getBBox()]\n",
    "    arr = work_img.getImage().getArray()\n",
    "\n",
    "    flags = afwMath.MEDIAN | afwMath.STDEVCLIP\n",
    "    statistics = afwMath.makeStatistics(work_img, flags) #, ccd.stat_ctrl)\n",
    "    median = statistics.getValue(afwMath.MEDIAN)\n",
    "    stdev = statistics.getValue(afwMath.STDEVCLIP)\n",
    "    \n",
    "    thresh = afwDetection.Threshold(100)\n",
    "    fs = afwDetection.FootprintSet(work_img, thresh) # detect hits\n",
    "    fs = afwDetection.FootprintSet(fs, 2, False) # grow the detection footprints\n",
    "    fs.makeHeavy(work_img)\n",
    "\n",
    "    foots = fs.getFootprints()\n",
    "\n",
    "    results_dict = dict(positions=[],\n",
    "                        zvals=[],\n",
    "                        sigmax=[],\n",
    "                        sigmay=[],\n",
    "                        dm=[],\n",
    "                        x0=[],\n",
    "                        y0=[],\n",
    "                        dn_fp=[],\n",
    "                        chiprob=[],\n",
    "                        chi2s=[],\n",
    "                        dofs=[],\n",
    "                        maxDNs=[],\n",
    "                        p9_data=[],\n",
    "                        p9_model=[],\n",
    "                        prect_data=[],\n",
    "                        xpeak=[],\n",
    "                        ypeak=[])\n",
    "\n",
    "    kwargs_dict = opt_dict.copy()\n",
    "    kwargs_dict.update(results_dict)\n",
    "    kwargs_dict['imarr'] = arr\n",
    "    kwargs_dict['stdev'] = stdev\n",
    "    kwargs_dict['meidan'] = median\n",
    "    \n",
    "    counts = []\n",
    "    \n",
    "    n_failed_fits = 0\n",
    "    n_good_fits = 0\n",
    "    \n",
    "    for foot in foots:\n",
    "        if foot.getImageArray().size < 25:  # throw out big footprints/CRs since we know the hits should be in a single pixel modulo the charge diffusion.\n",
    "            counts.append(numpy.sum(foot.getImageArray()))\n",
    "        #print(foot.getImageArray())\n",
    "        results = fit_single_footprint(foot, **kwargs_dict)\n",
    "        \n",
    "        if results == 0:\n",
    "            n_good_fits += 1 \n",
    "        else:\n",
    "            n_failed_fits += 1\n",
    "\n",
    "    ccd_results_list.append(results_dict)\n",
    "    if outfile_base is None:\n",
    "        outstream = sys.stdout\n",
    "    else:\n",
    "        outstream = open(\"%s_%02i.yaml\" %(outfile_base, iamp), 'w')\n",
    "    yaml.dump(results_dict, outstream)\n",
    "    if outfile_base is not None:\n",
    "        outstream.close()\n",
    "    \n",
    "    #hist = numpy.histogram(counts, bins=2100.+numpy.array(range(80))*10.) # generate distribution to fit\n",
    "\n",
    "    #y = hist[0]\n",
    "    #x = [(hist[1][i]+hist[1][i+1])/2 for i in range(len(hist[1])-1)]\n",
    "\n",
    "    #fit = leastsq(double_gaussian_fit, [50.,2270.,50.,10.,2550.,40.], args=(x, y)) # starting parameters were determined by examining a representative distribution\n",
    "    #xs.append(x)\n",
    "    #ys.append(y)\n",
    "    #fits.append(fit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_channel = '{}_test_channel'.format(os.environ['USER'])\n",
    "server = 'https://lsst-lspdev.ncsa.illinois.edu'\n",
    "\n",
    "ff='{}/firefly/slate.html?__wsch={}'.format(server, my_channel)\n",
    "IFrame(ff,800,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FE55_psf_func\n",
    "FE55_psf_func.chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilehist_base = \"FE55_cluster_hists\"\n",
    "\n",
    "bin_dict = dict(sigmax=(0.25, 0.75, 50),\n",
    "                sigmay=(0.25, 0.75, 50))\n",
    "ccd_hists_list = []\n",
    "for iamp, ccd_results in enumerate(ccd_results_list):\n",
    "    ccd_hists = stats_utils.bin_lists(ccd_results, bin_dict)\n",
    "    ccd_hists_list.append(ccd_hists)\n",
    "    \n",
    "    if outfilehist_base is None:\n",
    "        outstream = sys.stdout\n",
    "    else:\n",
    "        outstream = open(\"%s_%02i.yaml\" %(outfilehist_base, iamp), 'w')\n",
    "    yaml.dump(ccd_hists, outstream)\n",
    "    if outfilehist_base is not None:\n",
    "        outstream.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afwDisplay.setDefaultBackend('firefly')\n",
    "afw_display = afwDisplay.getDisplay(frame=1, \n",
    "                                    name=my_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaplay the frame after ISR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afw_display.mtv(result.exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot distributions for all 16 amps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, ccd_hists in enumerate(ccd_hists_list):\n",
    "    sigmax_data = ccd_hists['sigmax']\n",
    "    hist_data = sigmax_data['hist']\n",
    "    bin_edges = hist_data[1]\n",
    "    x = (bin_edges[0:-1] + bin_edges[1:]) /2.\n",
    "    y = hist_data[0]\n",
    "    yerr = numpy.sqrt(y)\n",
    "    fit = sigmax_data['fit']\n",
    "    indx = i%4\n",
    "    indy = i//4\n",
    "    if fit is not None:\n",
    "        axs[indx][indy].errorbar(x, y, yerr=yerr, c='b')\n",
    "        axs[indx][indy].plot(x, stats_utils.single_gaussian(x, fit[0]), c='r')\n",
    "    if indx == 3:\n",
    "        axs[indx][indy].set_xlabel('sigma_x')\n",
    "    if indy == 0:\n",
    "        axs[indx][indy].set_ylabel('N clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afw_display.mtv(work_img) # have a look at an example amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FE55_electrons = 1594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate gain and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(16):\n",
    "#    print(\"Gain for amp %s -- %.5f\"%(detector[i].getName(), FE55_electrons/fits[i][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
